{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be683df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17328084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440 440\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('lena.png')\n",
    "\n",
    "bwimg = img.convert(\"L\")\n",
    "w,h =bwimg.size\n",
    "\n",
    "print(w,h)\n",
    "\n",
    "nimg = np.array(bwimg)\n",
    "\n",
    "sobel_horizontal=[[-1, 0, 1],\n",
    "                  [-2, 0, 2],\n",
    "                  [-1, 0, 1]]\n",
    "\n",
    "sobel_vertical=[[-1, -2, -1],\n",
    "                [0, 0, 0],\n",
    "                [1, 2, 1]]\n",
    "\n",
    "\n",
    "def convolution(image,kernel,padding):\n",
    "    iw,ih =image.shape\n",
    "    kw,kh =kernel.shape\n",
    "\n",
    "    if padding=='same':\n",
    "        pad_h = kh//2\n",
    "        pad_w = kw//2\n",
    "    elif padding=='valid':\n",
    "        pad_h=pad_w=0\n",
    "    elif isinstance(padding,int):\n",
    "        pad_h = pad_w = padding\n",
    "    else:\n",
    "        raise ValueError(\"Invalid padding option\")\n",
    "    \n",
    "    #padding the image\n",
    "    padded_image = np.pad(image,((pad_h,pad_h),(pad_w,pad_w)),mode='constant')\n",
    "\n",
    "    #output size\n",
    "    oh = ih if padding=='same' else ih - kh + 1\n",
    "    ow = iw if padding=='same' else iw - kw + 1\n",
    "\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e36fb71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6. 14. 17. 11.  3.]\n",
      " [14. 12. 12. 17. 11.]\n",
      " [ 8. 10. 17. 19. 13.]\n",
      " [11.  9.  6. 14. 12.]\n",
      " [ 6.  4.  4.  6.  4.]]\n"
     ]
    }
   ],
   "source": [
    "a= np.array([[3,3,2,1,0],\n",
    "    [0,0,1,3,1],\n",
    "    [3,1,2,2,3],\n",
    "    [2,0,0,2,2],\n",
    "    [2,0,0,0,1]])\n",
    "\n",
    "k = np.array([[0,1,2],\n",
    "     [2,2,0],\n",
    "     [0,1,2]])\n",
    "\n",
    "ah,aw = a.shape\n",
    "kh,kw = k.shape\n",
    "\n",
    "#padding to preserve the size (i.e output size same as input)\n",
    "pad_h=kh//2\n",
    "pad_w=kw//2\n",
    "\n",
    "a_padded = np.zeros((ah+2*pad_h, aw+2*pad_w))\n",
    "a_padded[pad_h:pad_h+ah, pad_w:pad_w+aw] = a\n",
    "\n",
    "# oh,ow =ah-kh+1,aw-kw+1\n",
    "output = np.zeros((ah,aw))\n",
    "for h in range(ah):\n",
    "    for w in range(aw):\n",
    "        region = a_padded[h:h+kh,w:w+kw]\n",
    "        output[h,w] = np.sum(region*k)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faaa5688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel:\n",
      " [[0 1 2]\n",
      " [2 2 0]\n",
      " [0 1 2]]\n",
      "Input:\n",
      " [[3 3 2 1 0]\n",
      " [0 0 1 3 1]\n",
      " [3 1 2 2 3]\n",
      " [2 0 0 2 2]\n",
      " [2 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Kernel:\\n\", k)\n",
    "print(\"Input:\\n\", a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6da231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6., 14., 17., 11.,  3.],\n",
      "        [14., 12., 12., 17., 11.],\n",
      "        [ 8., 10., 17., 19., 13.],\n",
      "        [11.,  9.,  6., 14., 12.],\n",
      "        [ 6.,  4.,  4.,  6.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Input 2D array (image)\n",
    "a = torch.tensor([[3, 3, 2, 1, 0],\n",
    "                  [0, 0, 1, 3, 1],\n",
    "                  [3, 1, 2, 2, 3],\n",
    "                  [2, 0, 0, 2, 2],\n",
    "                  [2, 0, 0, 0, 1]], dtype=torch.float32)\n",
    "\n",
    "# Kernel\n",
    "k = torch.tensor([[0, 1, 2],\n",
    "                  [2, 2, 0],\n",
    "                  [0, 1, 2]], dtype=torch.float32)\n",
    "\n",
    "# Reshape for conv2d:\n",
    "# a: (1, 1, H, W)\n",
    "# k: (1, 1, kh, kw)\n",
    "a = a.unsqueeze(0).unsqueeze(0)         # shape: (1, 1, 5, 5)\n",
    "k = k.unsqueeze(0).unsqueeze(0)         # shape: (1, 1, 3, 3)\n",
    "\n",
    "# Apply convolution with padding=1 (to preserve size)\n",
    "output = F.conv2d(a, k, padding=1)\n",
    "\n",
    "# Remove extra dimensions\n",
    "print(output.squeeze())  # shape: (5, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f3194f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = Image.open('profileimg2.jpg').convert('L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3307ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2305, 2305)\n",
      "[[ 955. 1337. 1337. ... 1568. 1568. 1120.]\n",
      " [1528. 1910. 1910. ... 2240. 2240. 1344.]\n",
      " [1528. 1910. 1910. ... 2240. 2240. 1344.]\n",
      " ...\n",
      " [ 302.  389.  386. ... 2360. 2370. 1416.]\n",
      " [ 349.  452.  451. ... 2370. 2357. 1399.]\n",
      " [ 226.  330.  340. ... 1592. 1617. 1160.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array(vs)\n",
    "\n",
    "print(a.shape)\n",
    "k = np.array([[0,1,2],\n",
    "     [2,2,0],\n",
    "     [0,1,2]])\n",
    "\n",
    "ah,aw = a.shape\n",
    "kh,kw = k.shape\n",
    "\n",
    "#padding to preserve the size (i.e output size same as input)\n",
    "pad_h=kh//2\n",
    "pad_w=kw//2\n",
    "\n",
    "a_padded = np.zeros((ah+2*pad_h, aw+2*pad_w))\n",
    "a_padded[pad_h:pad_h+ah, pad_w:pad_w+aw] = a\n",
    "\n",
    "# oh,ow =ah-kh+1,aw-kw+1\n",
    "output = np.zeros((ah,aw))\n",
    "for h in range(ah):\n",
    "    for w in range(aw):\n",
    "        region = a_padded[h:h+kh,w:w+kw]\n",
    "        output[h,w] = np.sum(region*k)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2888d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize output to 0–255\n",
    "output -= output.min()\n",
    "output = output / output.max() * 255\n",
    "output = output.astype(np.uint8)\n",
    "\n",
    "# Convert to image and show\n",
    "convvs = Image.fromarray(output)\n",
    "convvs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7501e4d",
   "metadata": {},
   "source": [
    "Convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "410f89ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernels\n",
    "#edge detection\n",
    "sobel_x = np.array([[-1, 0, 1],\n",
    "                    [-2, 0, 2],\n",
    "                    [-1, 0, 1]])\n",
    "\n",
    "sobel_y = np.array([[-1, -2, -1],\n",
    "                    [ 0,  0,  0],\n",
    "                    [ 1,  2,  1]])\n",
    "\n",
    "laplacian = np.array([[ 0, -1,  0],\n",
    "                      [-1,  4, -1],\n",
    "                      [ 0, -1,  0]])\n",
    "\n",
    "#Blur Gaussian\n",
    "gaussian = (1/16) * np.array([[1, 2, 1],\n",
    "                              [2, 4, 2],\n",
    "                              [1, 2, 1]])\n",
    "\n",
    "box_blur = (1/9) * np.ones((3, 3))\n",
    "\n",
    "emboss = np.array([[-2, -1, 0],\n",
    "                   [-1,  1, 1],\n",
    "                   [ 0,  1, 2]])\n",
    "\n",
    "outline =10*np.array([[-1, -1, -1],\n",
    "                    [-1,  8, -1],\n",
    "                    [-1, -1, -1]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dcb34dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution(img, kernel):\n",
    "    a=np.array(img)\n",
    "    k=kernel\n",
    "    ah,aw = a.shape\n",
    "    kh,kw = k.shape\n",
    "\n",
    "    #padding to preserve the size (i.e output size same as input)\n",
    "    pad_h=kh//2\n",
    "    pad_w=kw//2\n",
    "\n",
    "    a_padded = np.zeros((ah+2*pad_h, aw+2*pad_w))\n",
    "    a_padded[pad_h:pad_h+ah, pad_w:pad_w+aw] = a\n",
    "\n",
    "    # oh,ow =ah-kh+1,aw-kw+1\n",
    "    output = np.zeros((ah,aw))\n",
    "    for h in range(ah):\n",
    "        for w in range(aw):\n",
    "            region = a_padded[h:h+kh,w:w+kw]\n",
    "            output[h,w] = np.sum(region*k)\n",
    "\n",
    "    # Normalize output to 0–255\n",
    "    output -= output.min()\n",
    "    output = output / output.max() * 255\n",
    "    output = output.astype(np.uint8)\n",
    "\n",
    "    # Convert to image and show\n",
    "    convvs = Image.fromarray(output)\n",
    "    convvs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "08866302",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('profileimg2.jpg').convert('L') #converting to grayscale\n",
    "convolution(img,sobel_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d81368",
   "metadata": {},
   "source": [
    "Convolution function with color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f5a7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_convolution(img, kernel):\n",
    "    a = np.array(img)  # shape: (H, W, 3) for RGB\n",
    "    k = kernel\n",
    "    kh, kw = k.shape\n",
    "    pad_h, pad_w = kh // 2, kw // 2\n",
    "\n",
    "    if len(a.shape) == 2:  # Grayscale\n",
    "        a = np.expand_dims(a, axis=2)\n",
    "\n",
    "    h, w, c = a.shape\n",
    "    output = np.zeros((h, w, c), dtype=np.float32)\n",
    "\n",
    "    for ch in range(c):  # Process each channel separately\n",
    "        channel = a[:, :, ch]\n",
    "        padded = np.pad(channel, ((pad_h, pad_h), (pad_w, pad_w)), mode='constant', constant_values=0)\n",
    "\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                region = padded[i:i+kh, j:j+kw]\n",
    "                output[i, j, ch] = np.sum(region * k)\n",
    "\n",
    "    # Normalize the entire image\n",
    "    output -= output.min()\n",
    "    output = output / output.max() * 255\n",
    "    output = output.astype(np.uint8)\n",
    "\n",
    "    # Convert back to image and show\n",
    "    conv_img = Image.fromarray(output)\n",
    "    conv_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "652864a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = Image.open('profileimg2.jpg').convert('RGB')\n",
    "color_convolution(color_img, sobel_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed18bd60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
